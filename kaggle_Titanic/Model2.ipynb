{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 891 rows of TRAIN.CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD CSV FILE\n",
    "df_train = pd.read_csv('train.csv')\n",
    "print ('Loaded',len(df_train),'rows of TRAIN.CSV')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Officer</th>\n",
       "      <th>Royalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Master  Miss  Mr  Mrs  Officer  Royalty\n",
       "0       0     0   1    0        0        0\n",
       "1       0     0   0    1        0        0\n",
       "2       0     1   0    0        0        0\n",
       "3       0     0   0    1        0        0\n",
       "4       0     0   1    0        0        0"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = pd.DataFrame()\n",
    "title[ 'Title' ] = df_train[ 'Name' ].map( lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n",
    "title_one = title[ 'Title' ]\n",
    "\n",
    "# a map of more aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "\n",
    "                    }\n",
    "\n",
    "# we map each title\n",
    "title[ 'Title' ] = title.Title.map( Title_Dictionary )\n",
    "\n",
    "#title = pd.concat( [ title , titles_dummies ] , axis = 1 )\n",
    "title = pd.get_dummies( title.Title )\n",
    "title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A/5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STON/O2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticket\n",
       "0       A/5\n",
       "1        PC\n",
       "2  STON/O2.\n",
       "3    simple\n",
       "4    simple"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticket_one = pd.DataFrame()\n",
    "ticket_one ['ticket'] = full[ 'Ticket' ].map( lambda name: name.split( ' ' )[0].strip() )\n",
    "\n",
    "count = 0\n",
    "for x in ticket_one['ticket'] :\n",
    " if x.isdigit() == True :\n",
    "    ticket_one['ticket'][count]=\"simple\"\n",
    " count =  count +1\n",
    "\n",
    "ticket_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FamilySize\n",
       "0           1\n",
       "1           1\n",
       "2           0\n",
       "3           1\n",
       "4           0"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family = pd.DataFrame()\n",
    "family['FamilySize'] = df_train['SibSp'] + df_train['Parch']\n",
    "family.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[ ['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] ]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S    Mr   \n",
       "1         1       1  female  38.0      1      0  71.2833        C   Mrs   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Miss   \n",
       "3         1       1  female  35.0      1      0  53.1000        S   Mrs   \n",
       "4         0       3    male  35.0      0      0   8.0500        S    Mr   \n",
       "\n",
       "   FamilySize  \n",
       "0           1  \n",
       "1           1  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat( [df_train,title_one, family ], axis=1  )\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 712 rows of TRAIN.CSV\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "print ('Loaded',len(df_train),'rows of TRAIN.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Y = df_train['Survived']\n",
    "Data_X =  df_train.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  FamilySize\n",
       "0       3    male  22.0      1      0   7.2500        S    Mr           1\n",
       "1       1  female  38.0      1      0  71.2833        C   Mrs           1\n",
       "2       3  female  26.0      0      0   7.9250        S  Miss           0\n",
       "3       1  female  35.0      1      0  53.1000        S   Mrs           1\n",
       "4       3    male  35.0      0      0   8.0500        S    Mr           0"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Data_X.shape)\n",
    "Data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Title  FamilySize\n",
       "0       3    1  22.0      1      0   7.2500         2      2           1\n",
       "1       1    0  38.0      1      0  71.2833         0      3           1\n",
       "2       3    0  26.0      0      0   7.9250         2      1           0\n",
       "3       1    0  35.0      1      0  53.1000         2      3           1\n",
       "4       3    1  35.0      0      0   8.0500         2      2           0"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labEnc_Sex = preprocessing.LabelEncoder()\n",
    "labEnc_Embarked = preprocessing.LabelEncoder()\n",
    "labEnc_Title = preprocessing.LabelEncoder()\n",
    "\n",
    "labEnc_Sex.fit(Data_X.Sex.values)\n",
    "Data_X['Sex'] = labEnc_Sex.transform(Data_X.Sex.values)\n",
    "\n",
    "labEnc_Embarked.fit(Data_X.Embarked.values.astype(str))\n",
    "Data_X['Embarked'] = labEnc_Embarked.transform(Data_X.Embarked.values.astype(str))\n",
    "\n",
    "labEnc_Title.fit(Data_X.Title.values.astype(str))\n",
    "Data_X['Title'] = labEnc_Title.transform(Data_X.Title.values.astype(str))\n",
    "\n",
    "Data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Title  FamilySize\n",
       "0       3    1  22.0      1      0   7.2500         2      2           1\n",
       "1       1    0  38.0      1      0  71.2833         0      3           1\n",
       "2       3    0  26.0      0      0   7.9250         2      1           0\n",
       "3       1    0  35.0      1      0  53.1000         2      3           1\n",
       "4       3    1  35.0      0      0   8.0500         2      2           0"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import Adam, Adamax\n",
    "\n",
    "#SPLIT TRAIN AND VALIDATION SET\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(Data_X, Data_Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function returning a compiled network\n",
    "def create_network():\n",
    "    \n",
    "    # Start neural network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(18,input_dim=9))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    #model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('selu'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # Return compiled network\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 498 samples, validate on 214 samples\n",
      "Epoch 1/300\n",
      "498/498 [==============================] - 33s 66ms/step - loss: 0.8830 - acc: 0.5141 - val_loss: 0.7720 - val_acc: 0.4159\n",
      "Epoch 2/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.8209 - acc: 0.5442 - val_loss: 0.7428 - val_acc: 0.4439\n",
      "Epoch 3/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.8085 - acc: 0.5442 - val_loss: 0.7306 - val_acc: 0.4673\n",
      "Epoch 4/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.7995 - acc: 0.5622 - val_loss: 0.7204 - val_acc: 0.4907\n",
      "Epoch 5/300\n",
      "498/498 [==============================] - 0s 255us/step - loss: 0.7549 - acc: 0.5602 - val_loss: 0.7140 - val_acc: 0.5140\n",
      "Epoch 6/300\n",
      "498/498 [==============================] - 0s 205us/step - loss: 0.7475 - acc: 0.5743 - val_loss: 0.7047 - val_acc: 0.5234\n",
      "Epoch 7/300\n",
      "498/498 [==============================] - 0s 183us/step - loss: 0.7546 - acc: 0.5924 - val_loss: 0.6939 - val_acc: 0.5374\n",
      "Epoch 8/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.7529 - acc: 0.5884 - val_loss: 0.6827 - val_acc: 0.6308\n",
      "Epoch 9/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.7333 - acc: 0.6145 - val_loss: 0.6728 - val_acc: 0.6729\n",
      "Epoch 10/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.7235 - acc: 0.6044 - val_loss: 0.6672 - val_acc: 0.6822\n",
      "Epoch 11/300\n",
      "498/498 [==============================] - 0s 187us/step - loss: 0.6940 - acc: 0.6606 - val_loss: 0.6614 - val_acc: 0.6776\n",
      "Epoch 12/300\n",
      "498/498 [==============================] - 0s 175us/step - loss: 0.6941 - acc: 0.6205 - val_loss: 0.6551 - val_acc: 0.6682\n",
      "Epoch 13/300\n",
      "498/498 [==============================] - 0s 199us/step - loss: 0.6766 - acc: 0.6586 - val_loss: 0.6489 - val_acc: 0.6729\n",
      "Epoch 14/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.6638 - acc: 0.6627 - val_loss: 0.6453 - val_acc: 0.6682\n",
      "Epoch 15/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.6720 - acc: 0.6426 - val_loss: 0.6418 - val_acc: 0.6682\n",
      "Epoch 16/300\n",
      "498/498 [==============================] - 0s 193us/step - loss: 0.6713 - acc: 0.6606 - val_loss: 0.6391 - val_acc: 0.6776\n",
      "Epoch 17/300\n",
      "498/498 [==============================] - 0s 217us/step - loss: 0.6348 - acc: 0.6787 - val_loss: 0.6367 - val_acc: 0.6822\n",
      "Epoch 18/300\n",
      "498/498 [==============================] - 0s 177us/step - loss: 0.6453 - acc: 0.6988 - val_loss: 0.6359 - val_acc: 0.6822\n",
      "Epoch 19/300\n",
      "498/498 [==============================] - 0s 169us/step - loss: 0.6311 - acc: 0.6807 - val_loss: 0.6345 - val_acc: 0.6822\n",
      "Epoch 20/300\n",
      "498/498 [==============================] - 0s 198us/step - loss: 0.6472 - acc: 0.6606 - val_loss: 0.6326 - val_acc: 0.6822\n",
      "Epoch 21/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.6591 - acc: 0.6647 - val_loss: 0.6312 - val_acc: 0.6822\n",
      "Epoch 22/300\n",
      "498/498 [==============================] - 0s 197us/step - loss: 0.6425 - acc: 0.6767 - val_loss: 0.6290 - val_acc: 0.6729\n",
      "Epoch 23/300\n",
      "498/498 [==============================] - 0s 207us/step - loss: 0.6603 - acc: 0.6506 - val_loss: 0.6271 - val_acc: 0.6776\n",
      "Epoch 24/300\n",
      "498/498 [==============================] - 0s 232us/step - loss: 0.6601 - acc: 0.6627 - val_loss: 0.6260 - val_acc: 0.6822\n",
      "Epoch 25/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.6207 - acc: 0.6787 - val_loss: 0.6249 - val_acc: 0.6869\n",
      "Epoch 26/300\n",
      "498/498 [==============================] - 0s 207us/step - loss: 0.6195 - acc: 0.6928 - val_loss: 0.6240 - val_acc: 0.6822\n",
      "Epoch 27/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5918 - acc: 0.6988 - val_loss: 0.6238 - val_acc: 0.6822\n",
      "Epoch 28/300\n",
      "498/498 [==============================] - 0s 183us/step - loss: 0.6334 - acc: 0.6667 - val_loss: 0.6237 - val_acc: 0.6916\n",
      "Epoch 29/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.6192 - acc: 0.6687 - val_loss: 0.6223 - val_acc: 0.6963\n",
      "Epoch 30/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.6197 - acc: 0.6888 - val_loss: 0.6213 - val_acc: 0.6916\n",
      "Epoch 31/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.6099 - acc: 0.7068 - val_loss: 0.6201 - val_acc: 0.6869\n",
      "Epoch 32/300\n",
      "498/498 [==============================] - 0s 185us/step - loss: 0.6093 - acc: 0.7108 - val_loss: 0.6179 - val_acc: 0.6822\n",
      "Epoch 33/300\n",
      "498/498 [==============================] - 0s 222us/step - loss: 0.6254 - acc: 0.6908 - val_loss: 0.6165 - val_acc: 0.6869\n",
      "Epoch 34/300\n",
      "498/498 [==============================] - 0s 261us/step - loss: 0.5972 - acc: 0.6787 - val_loss: 0.6161 - val_acc: 0.6869\n",
      "Epoch 35/300\n",
      "498/498 [==============================] - 0s 379us/step - loss: 0.6223 - acc: 0.6506 - val_loss: 0.6169 - val_acc: 0.6822\n",
      "Epoch 36/300\n",
      "498/498 [==============================] - 0s 306us/step - loss: 0.6003 - acc: 0.7108 - val_loss: 0.6161 - val_acc: 0.6869\n",
      "Epoch 37/300\n",
      "498/498 [==============================] - 0s 297us/step - loss: 0.6150 - acc: 0.6888 - val_loss: 0.6139 - val_acc: 0.6869\n",
      "Epoch 38/300\n",
      "498/498 [==============================] - 0s 271us/step - loss: 0.5941 - acc: 0.7048 - val_loss: 0.6124 - val_acc: 0.6916\n",
      "Epoch 39/300\n",
      "498/498 [==============================] - 0s 253us/step - loss: 0.5881 - acc: 0.7108 - val_loss: 0.6115 - val_acc: 0.6916\n",
      "Epoch 40/300\n",
      "498/498 [==============================] - 0s 271us/step - loss: 0.5883 - acc: 0.7028 - val_loss: 0.6105 - val_acc: 0.6963\n",
      "Epoch 41/300\n",
      "498/498 [==============================] - 0s 234us/step - loss: 0.5745 - acc: 0.7309 - val_loss: 0.6091 - val_acc: 0.7056\n",
      "Epoch 42/300\n",
      "498/498 [==============================] - 0s 279us/step - loss: 0.6048 - acc: 0.6908 - val_loss: 0.6074 - val_acc: 0.7056\n",
      "Epoch 43/300\n",
      "498/498 [==============================] - 0s 250us/step - loss: 0.5959 - acc: 0.7088 - val_loss: 0.6058 - val_acc: 0.7056\n",
      "Epoch 44/300\n",
      "498/498 [==============================] - 0s 284us/step - loss: 0.5835 - acc: 0.7289 - val_loss: 0.6037 - val_acc: 0.7056\n",
      "Epoch 45/300\n",
      "498/498 [==============================] - 0s 266us/step - loss: 0.5784 - acc: 0.7088 - val_loss: 0.6011 - val_acc: 0.7103\n",
      "Epoch 46/300\n",
      "498/498 [==============================] - 0s 234us/step - loss: 0.5696 - acc: 0.7028 - val_loss: 0.5993 - val_acc: 0.7103\n",
      "Epoch 47/300\n",
      "498/498 [==============================] - 0s 195us/step - loss: 0.5850 - acc: 0.7169 - val_loss: 0.5983 - val_acc: 0.7103\n",
      "Epoch 48/300\n",
      "498/498 [==============================] - 0s 242us/step - loss: 0.5805 - acc: 0.7088 - val_loss: 0.5979 - val_acc: 0.7103\n",
      "Epoch 49/300\n",
      "498/498 [==============================] - 0s 251us/step - loss: 0.5875 - acc: 0.7048 - val_loss: 0.5968 - val_acc: 0.7103\n",
      "Epoch 50/300\n",
      "498/498 [==============================] - 0s 261us/step - loss: 0.5858 - acc: 0.7068 - val_loss: 0.5947 - val_acc: 0.7103\n",
      "Epoch 51/300\n",
      "498/498 [==============================] - 0s 249us/step - loss: 0.5849 - acc: 0.6867 - val_loss: 0.5922 - val_acc: 0.7056\n",
      "Epoch 52/300\n",
      "498/498 [==============================] - 0s 273us/step - loss: 0.5830 - acc: 0.7108 - val_loss: 0.5903 - val_acc: 0.7056\n",
      "Epoch 53/300\n",
      "498/498 [==============================] - 0s 285us/step - loss: 0.5821 - acc: 0.7088 - val_loss: 0.5902 - val_acc: 0.7009\n",
      "Epoch 54/300\n",
      "498/498 [==============================] - 0s 225us/step - loss: 0.5725 - acc: 0.7088 - val_loss: 0.5903 - val_acc: 0.7009\n",
      "Epoch 55/300\n",
      "498/498 [==============================] - 0s 229us/step - loss: 0.5765 - acc: 0.7169 - val_loss: 0.5909 - val_acc: 0.6963\n",
      "Epoch 56/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.5776 - acc: 0.7008 - val_loss: 0.5898 - val_acc: 0.6869\n",
      "Epoch 57/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5661 - acc: 0.7189 - val_loss: 0.5864 - val_acc: 0.7009\n",
      "Epoch 58/300\n",
      "498/498 [==============================] - 0s 210us/step - loss: 0.5664 - acc: 0.7289 - val_loss: 0.5836 - val_acc: 0.7056\n",
      "Epoch 59/300\n",
      "498/498 [==============================] - 0s 230us/step - loss: 0.5642 - acc: 0.7169 - val_loss: 0.5827 - val_acc: 0.7056\n",
      "Epoch 60/300\n",
      "498/498 [==============================] - 0s 227us/step - loss: 0.5746 - acc: 0.7088 - val_loss: 0.5840 - val_acc: 0.6963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "498/498 [==============================] - 0s 232us/step - loss: 0.5687 - acc: 0.7149 - val_loss: 0.5821 - val_acc: 0.6963\n",
      "Epoch 62/300\n",
      "498/498 [==============================] - 0s 212us/step - loss: 0.5675 - acc: 0.7329 - val_loss: 0.5817 - val_acc: 0.6963\n",
      "Epoch 63/300\n",
      "498/498 [==============================] - 0s 197us/step - loss: 0.5542 - acc: 0.7169 - val_loss: 0.5827 - val_acc: 0.6916\n",
      "Epoch 64/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5581 - acc: 0.7249 - val_loss: 0.5829 - val_acc: 0.6869\n",
      "Epoch 65/300\n",
      "498/498 [==============================] - 0s 193us/step - loss: 0.5756 - acc: 0.7068 - val_loss: 0.5797 - val_acc: 0.6869\n",
      "Epoch 66/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.5503 - acc: 0.7209 - val_loss: 0.5785 - val_acc: 0.7009\n",
      "Epoch 67/300\n",
      "498/498 [==============================] - 0s 235us/step - loss: 0.5634 - acc: 0.7169 - val_loss: 0.5765 - val_acc: 0.7056\n",
      "Epoch 68/300\n",
      "498/498 [==============================] - 0s 199us/step - loss: 0.5639 - acc: 0.7209 - val_loss: 0.5769 - val_acc: 0.6916\n",
      "Epoch 69/300\n",
      "498/498 [==============================] - 0s 225us/step - loss: 0.5799 - acc: 0.7129 - val_loss: 0.5780 - val_acc: 0.7009\n",
      "Epoch 70/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.5693 - acc: 0.7309 - val_loss: 0.5790 - val_acc: 0.7056\n",
      "Epoch 71/300\n",
      "498/498 [==============================] - 0s 243us/step - loss: 0.5608 - acc: 0.7229 - val_loss: 0.5763 - val_acc: 0.7056\n",
      "Epoch 72/300\n",
      "498/498 [==============================] - 0s 215us/step - loss: 0.5692 - acc: 0.7048 - val_loss: 0.5731 - val_acc: 0.6869\n",
      "Epoch 73/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5672 - acc: 0.7229 - val_loss: 0.5699 - val_acc: 0.6916\n",
      "Epoch 74/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5895 - acc: 0.7289 - val_loss: 0.5685 - val_acc: 0.6916\n",
      "Epoch 75/300\n",
      "498/498 [==============================] - 0s 248us/step - loss: 0.5715 - acc: 0.7048 - val_loss: 0.5682 - val_acc: 0.6963\n",
      "Epoch 76/300\n",
      "498/498 [==============================] - 0s 231us/step - loss: 0.5545 - acc: 0.7048 - val_loss: 0.5692 - val_acc: 0.6963\n",
      "Epoch 77/300\n",
      "498/498 [==============================] - 0s 228us/step - loss: 0.5662 - acc: 0.7048 - val_loss: 0.5731 - val_acc: 0.6963\n",
      "Epoch 78/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5562 - acc: 0.7369 - val_loss: 0.5743 - val_acc: 0.6963\n",
      "Epoch 79/300\n",
      "498/498 [==============================] - 0s 218us/step - loss: 0.5586 - acc: 0.7129 - val_loss: 0.5711 - val_acc: 0.6916\n",
      "Epoch 80/300\n",
      "498/498 [==============================] - 0s 244us/step - loss: 0.5648 - acc: 0.7108 - val_loss: 0.5722 - val_acc: 0.6869\n",
      "Epoch 81/300\n",
      "498/498 [==============================] - 0s 231us/step - loss: 0.5598 - acc: 0.7410 - val_loss: 0.5735 - val_acc: 0.6963\n",
      "Epoch 82/300\n",
      "498/498 [==============================] - 0s 207us/step - loss: 0.5550 - acc: 0.7309 - val_loss: 0.5745 - val_acc: 0.6963\n",
      "Epoch 83/300\n",
      "498/498 [==============================] - 0s 191us/step - loss: 0.5688 - acc: 0.7430 - val_loss: 0.5729 - val_acc: 0.7009\n",
      "Epoch 84/300\n",
      "498/498 [==============================] - 0s 224us/step - loss: 0.5431 - acc: 0.7289 - val_loss: 0.5670 - val_acc: 0.7009\n",
      "Epoch 85/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.5474 - acc: 0.7369 - val_loss: 0.5633 - val_acc: 0.7009\n",
      "Epoch 86/300\n",
      "498/498 [==============================] - 0s 225us/step - loss: 0.5452 - acc: 0.7329 - val_loss: 0.5599 - val_acc: 0.7196\n",
      "Epoch 87/300\n",
      "498/498 [==============================] - 0s 232us/step - loss: 0.5725 - acc: 0.7048 - val_loss: 0.5628 - val_acc: 0.6963\n",
      "Epoch 88/300\n",
      "498/498 [==============================] - 0s 244us/step - loss: 0.5361 - acc: 0.7369 - val_loss: 0.5656 - val_acc: 0.6916\n",
      "Epoch 89/300\n",
      "498/498 [==============================] - 0s 239us/step - loss: 0.5557 - acc: 0.7189 - val_loss: 0.5654 - val_acc: 0.6963\n",
      "Epoch 90/300\n",
      "498/498 [==============================] - 0s 201us/step - loss: 0.5429 - acc: 0.7169 - val_loss: 0.5649 - val_acc: 0.6963\n",
      "Epoch 91/300\n",
      "498/498 [==============================] - 0s 197us/step - loss: 0.5455 - acc: 0.7410 - val_loss: 0.5621 - val_acc: 0.6963\n",
      "Epoch 92/300\n",
      "498/498 [==============================] - 0s 228us/step - loss: 0.5447 - acc: 0.7410 - val_loss: 0.5610 - val_acc: 0.6963\n",
      "Epoch 93/300\n",
      "498/498 [==============================] - 0s 234us/step - loss: 0.5420 - acc: 0.7309 - val_loss: 0.5613 - val_acc: 0.7009\n",
      "Epoch 94/300\n",
      "498/498 [==============================] - 0s 247us/step - loss: 0.5431 - acc: 0.7570 - val_loss: 0.5569 - val_acc: 0.7009\n",
      "Epoch 95/300\n",
      "498/498 [==============================] - 0s 241us/step - loss: 0.5286 - acc: 0.7209 - val_loss: 0.5532 - val_acc: 0.7009\n",
      "Epoch 96/300\n",
      "498/498 [==============================] - 0s 241us/step - loss: 0.5475 - acc: 0.7289 - val_loss: 0.5626 - val_acc: 0.7056\n",
      "Epoch 97/300\n",
      "498/498 [==============================] - 0s 236us/step - loss: 0.5451 - acc: 0.7390 - val_loss: 0.5645 - val_acc: 0.7056\n",
      "Epoch 98/300\n",
      "498/498 [==============================] - 0s 202us/step - loss: 0.5339 - acc: 0.7530 - val_loss: 0.5579 - val_acc: 0.6963\n",
      "Epoch 99/300\n",
      "498/498 [==============================] - 0s 227us/step - loss: 0.5377 - acc: 0.7470 - val_loss: 0.5558 - val_acc: 0.6963\n",
      "Epoch 100/300\n",
      "498/498 [==============================] - 0s 237us/step - loss: 0.5513 - acc: 0.7289 - val_loss: 0.5549 - val_acc: 0.6916\n",
      "Epoch 101/300\n",
      "498/498 [==============================] - 0s 233us/step - loss: 0.5461 - acc: 0.7570 - val_loss: 0.5512 - val_acc: 0.7009\n",
      "Epoch 102/300\n",
      "498/498 [==============================] - 0s 227us/step - loss: 0.5480 - acc: 0.7309 - val_loss: 0.5544 - val_acc: 0.7009\n",
      "Epoch 103/300\n",
      "498/498 [==============================] - 0s 216us/step - loss: 0.5495 - acc: 0.7269 - val_loss: 0.5560 - val_acc: 0.6963\n",
      "Epoch 104/300\n",
      "498/498 [==============================] - 0s 226us/step - loss: 0.5609 - acc: 0.7229 - val_loss: 0.5555 - val_acc: 0.6963\n",
      "Epoch 105/300\n",
      "498/498 [==============================] - 0s 227us/step - loss: 0.5610 - acc: 0.7169 - val_loss: 0.5573 - val_acc: 0.7009\n",
      "Epoch 106/300\n",
      "498/498 [==============================] - 0s 243us/step - loss: 0.5264 - acc: 0.7631 - val_loss: 0.5602 - val_acc: 0.7150\n",
      "Epoch 107/300\n",
      "498/498 [==============================] - 0s 199us/step - loss: 0.5492 - acc: 0.7410 - val_loss: 0.5647 - val_acc: 0.7290\n",
      "Epoch 108/300\n",
      "498/498 [==============================] - 0s 209us/step - loss: 0.5471 - acc: 0.7450 - val_loss: 0.5713 - val_acc: 0.7243\n",
      "Epoch 109/300\n",
      "498/498 [==============================] - 0s 234us/step - loss: 0.5393 - acc: 0.7530 - val_loss: 0.5706 - val_acc: 0.7290\n",
      "Epoch 110/300\n",
      "498/498 [==============================] - 0s 230us/step - loss: 0.5478 - acc: 0.7209 - val_loss: 0.5669 - val_acc: 0.7196\n",
      "Epoch 111/300\n",
      "498/498 [==============================] - 0s 245us/step - loss: 0.5352 - acc: 0.7490 - val_loss: 0.5579 - val_acc: 0.7103\n",
      "Epoch 112/300\n",
      "498/498 [==============================] - 0s 279us/step - loss: 0.5257 - acc: 0.7570 - val_loss: 0.5507 - val_acc: 0.7056\n",
      "Epoch 113/300\n",
      "498/498 [==============================] - 0s 268us/step - loss: 0.5465 - acc: 0.7269 - val_loss: 0.5469 - val_acc: 0.7150\n",
      "Epoch 114/300\n",
      "498/498 [==============================] - 0s 278us/step - loss: 0.5431 - acc: 0.7269 - val_loss: 0.5512 - val_acc: 0.7150\n",
      "Epoch 115/300\n",
      "498/498 [==============================] - 0s 275us/step - loss: 0.5513 - acc: 0.7209 - val_loss: 0.5610 - val_acc: 0.7243\n",
      "Epoch 116/300\n",
      "498/498 [==============================] - 0s 259us/step - loss: 0.5454 - acc: 0.7510 - val_loss: 0.5730 - val_acc: 0.7430\n",
      "Epoch 117/300\n",
      "498/498 [==============================] - 0s 394us/step - loss: 0.5354 - acc: 0.7229 - val_loss: 0.5728 - val_acc: 0.7243\n",
      "Epoch 118/300\n",
      "498/498 [==============================] - 0s 552us/step - loss: 0.5318 - acc: 0.7369 - val_loss: 0.5685 - val_acc: 0.7336\n",
      "Epoch 119/300\n",
      "498/498 [==============================] - 0s 596us/step - loss: 0.5294 - acc: 0.7470 - val_loss: 0.5657 - val_acc: 0.7150\n",
      "Epoch 120/300\n",
      "498/498 [==============================] - 1s 3ms/step - loss: 0.5245 - acc: 0.7410 - val_loss: 0.5670 - val_acc: 0.7383\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 [==============================] - 0s 471us/step - loss: 0.5125 - acc: 0.7470 - val_loss: 0.5664 - val_acc: 0.7290\n",
      "Epoch 122/300\n",
      "498/498 [==============================] - 0s 445us/step - loss: 0.5393 - acc: 0.7450 - val_loss: 0.5616 - val_acc: 0.7336\n",
      "Epoch 123/300\n",
      "498/498 [==============================] - 0s 340us/step - loss: 0.5392 - acc: 0.7450 - val_loss: 0.5634 - val_acc: 0.7336\n",
      "Epoch 124/300\n",
      "498/498 [==============================] - 0s 320us/step - loss: 0.5255 - acc: 0.7309 - val_loss: 0.5641 - val_acc: 0.7243\n",
      "Epoch 125/300\n",
      "498/498 [==============================] - 0s 260us/step - loss: 0.5430 - acc: 0.7309 - val_loss: 0.5616 - val_acc: 0.7243\n",
      "Epoch 126/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.5422 - acc: 0.7490 - val_loss: 0.5663 - val_acc: 0.7523\n",
      "Epoch 127/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.5328 - acc: 0.7309 - val_loss: 0.5667 - val_acc: 0.7570\n",
      "Epoch 128/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.5197 - acc: 0.7631 - val_loss: 0.5721 - val_acc: 0.7523\n",
      "Epoch 129/300\n",
      "498/498 [==============================] - 0s 212us/step - loss: 0.5213 - acc: 0.7570 - val_loss: 0.5740 - val_acc: 0.7523\n",
      "Epoch 130/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5472 - acc: 0.7430 - val_loss: 0.5707 - val_acc: 0.7336\n",
      "Epoch 131/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.5434 - acc: 0.7349 - val_loss: 0.5618 - val_acc: 0.7290\n",
      "Epoch 132/300\n",
      "498/498 [==============================] - 0s 272us/step - loss: 0.5249 - acc: 0.7590 - val_loss: 0.5569 - val_acc: 0.7056\n",
      "Epoch 133/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5320 - acc: 0.7470 - val_loss: 0.5631 - val_acc: 0.7056\n",
      "Epoch 134/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.5343 - acc: 0.7450 - val_loss: 0.5730 - val_acc: 0.7290\n",
      "Epoch 135/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5438 - acc: 0.7088 - val_loss: 0.5749 - val_acc: 0.7383\n",
      "Epoch 136/300\n",
      "498/498 [==============================] - 0s 216us/step - loss: 0.5400 - acc: 0.7490 - val_loss: 0.5687 - val_acc: 0.7383\n",
      "Epoch 137/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5309 - acc: 0.7510 - val_loss: 0.5724 - val_acc: 0.7336\n",
      "Epoch 138/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5468 - acc: 0.7530 - val_loss: 0.5803 - val_acc: 0.7570\n",
      "Epoch 139/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5213 - acc: 0.7530 - val_loss: 0.5769 - val_acc: 0.7523\n",
      "Epoch 140/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5220 - acc: 0.7691 - val_loss: 0.5635 - val_acc: 0.7477\n",
      "Epoch 141/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.5321 - acc: 0.7369 - val_loss: 0.5582 - val_acc: 0.7243\n",
      "Epoch 142/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5163 - acc: 0.7410 - val_loss: 0.5513 - val_acc: 0.7290\n",
      "Epoch 143/300\n",
      "498/498 [==============================] - 0s 234us/step - loss: 0.5259 - acc: 0.7550 - val_loss: 0.5550 - val_acc: 0.7243\n",
      "Epoch 144/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5176 - acc: 0.7590 - val_loss: 0.5601 - val_acc: 0.7383\n",
      "Epoch 145/300\n",
      "498/498 [==============================] - 0s 210us/step - loss: 0.5269 - acc: 0.7490 - val_loss: 0.5591 - val_acc: 0.7383\n",
      "Epoch 146/300\n",
      "498/498 [==============================] - 0s 202us/step - loss: 0.5524 - acc: 0.7008 - val_loss: 0.5556 - val_acc: 0.7383\n",
      "Epoch 147/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.5242 - acc: 0.7631 - val_loss: 0.5580 - val_acc: 0.7523\n",
      "Epoch 148/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.5318 - acc: 0.7349 - val_loss: 0.5651 - val_acc: 0.7477\n",
      "Epoch 149/300\n",
      "498/498 [==============================] - 0s 202us/step - loss: 0.5420 - acc: 0.7490 - val_loss: 0.5706 - val_acc: 0.7523\n",
      "Epoch 150/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5259 - acc: 0.7550 - val_loss: 0.5634 - val_acc: 0.7383\n",
      "Epoch 151/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5151 - acc: 0.7671 - val_loss: 0.5607 - val_acc: 0.7477\n",
      "Epoch 152/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.5237 - acc: 0.7771 - val_loss: 0.5618 - val_acc: 0.7430\n",
      "Epoch 153/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5164 - acc: 0.7530 - val_loss: 0.5661 - val_acc: 0.7430\n",
      "Epoch 154/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5082 - acc: 0.7631 - val_loss: 0.5676 - val_acc: 0.7430\n",
      "Epoch 155/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5273 - acc: 0.7470 - val_loss: 0.5704 - val_acc: 0.7523\n",
      "Epoch 156/300\n",
      "498/498 [==============================] - 0s 222us/step - loss: 0.4953 - acc: 0.7711 - val_loss: 0.5699 - val_acc: 0.7336\n",
      "Epoch 157/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.5277 - acc: 0.7289 - val_loss: 0.5616 - val_acc: 0.7243\n",
      "Epoch 158/300\n",
      "498/498 [==============================] - 0s 232us/step - loss: 0.5316 - acc: 0.7470 - val_loss: 0.5564 - val_acc: 0.7150\n",
      "Epoch 159/300\n",
      "498/498 [==============================] - 0s 214us/step - loss: 0.5334 - acc: 0.7450 - val_loss: 0.5572 - val_acc: 0.7150\n",
      "Epoch 160/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5055 - acc: 0.7871 - val_loss: 0.5610 - val_acc: 0.7430\n",
      "Epoch 161/300\n",
      "498/498 [==============================] - 0s 212us/step - loss: 0.5354 - acc: 0.7410 - val_loss: 0.5551 - val_acc: 0.7430\n",
      "Epoch 162/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5141 - acc: 0.7711 - val_loss: 0.5593 - val_acc: 0.7617\n",
      "Epoch 163/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5190 - acc: 0.7390 - val_loss: 0.5690 - val_acc: 0.7664\n",
      "Epoch 164/300\n",
      "498/498 [==============================] - 0s 242us/step - loss: 0.5399 - acc: 0.7470 - val_loss: 0.5711 - val_acc: 0.7664\n",
      "Epoch 165/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5231 - acc: 0.7590 - val_loss: 0.5727 - val_acc: 0.7617\n",
      "Epoch 166/300\n",
      "498/498 [==============================] - 0s 300us/step - loss: 0.5185 - acc: 0.7711 - val_loss: 0.5640 - val_acc: 0.7430\n",
      "Epoch 167/300\n",
      "498/498 [==============================] - 0s 202us/step - loss: 0.5133 - acc: 0.7490 - val_loss: 0.5579 - val_acc: 0.7477\n",
      "Epoch 168/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.5082 - acc: 0.7731 - val_loss: 0.5470 - val_acc: 0.7336\n",
      "Epoch 169/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5162 - acc: 0.7570 - val_loss: 0.5378 - val_acc: 0.7336\n",
      "Epoch 170/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5443 - acc: 0.7390 - val_loss: 0.5475 - val_acc: 0.7336\n",
      "Epoch 171/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.5213 - acc: 0.7851 - val_loss: 0.5612 - val_acc: 0.7477\n",
      "Epoch 172/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5087 - acc: 0.7631 - val_loss: 0.5657 - val_acc: 0.7523\n",
      "Epoch 173/300\n",
      "498/498 [==============================] - 0s 230us/step - loss: 0.5070 - acc: 0.7751 - val_loss: 0.5669 - val_acc: 0.7664\n",
      "Epoch 174/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5091 - acc: 0.7410 - val_loss: 0.5587 - val_acc: 0.7523\n",
      "Epoch 175/300\n",
      "498/498 [==============================] - 0s 212us/step - loss: 0.5368 - acc: 0.7510 - val_loss: 0.5497 - val_acc: 0.7383\n",
      "Epoch 176/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.4992 - acc: 0.7711 - val_loss: 0.5526 - val_acc: 0.7336\n",
      "Epoch 177/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5018 - acc: 0.7711 - val_loss: 0.5526 - val_acc: 0.7336\n",
      "Epoch 178/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5166 - acc: 0.7550 - val_loss: 0.5565 - val_acc: 0.7383\n",
      "Epoch 179/300\n",
      "498/498 [==============================] - 0s 198us/step - loss: 0.5112 - acc: 0.7651 - val_loss: 0.5571 - val_acc: 0.7523\n",
      "Epoch 180/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5131 - acc: 0.7610 - val_loss: 0.5522 - val_acc: 0.7477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5016 - acc: 0.7811 - val_loss: 0.5458 - val_acc: 0.7430\n",
      "Epoch 182/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5150 - acc: 0.7430 - val_loss: 0.5438 - val_acc: 0.7477\n",
      "Epoch 183/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5223 - acc: 0.7651 - val_loss: 0.5419 - val_acc: 0.7477\n",
      "Epoch 184/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5199 - acc: 0.7731 - val_loss: 0.5420 - val_acc: 0.7477\n",
      "Epoch 185/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5307 - acc: 0.7590 - val_loss: 0.5330 - val_acc: 0.7430\n",
      "Epoch 186/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.4944 - acc: 0.7691 - val_loss: 0.5230 - val_acc: 0.7430\n",
      "Epoch 187/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.5324 - acc: 0.7711 - val_loss: 0.5307 - val_acc: 0.7477\n",
      "Epoch 188/300\n",
      "498/498 [==============================] - 0s 208us/step - loss: 0.5052 - acc: 0.7831 - val_loss: 0.5546 - val_acc: 0.7757\n",
      "Epoch 189/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5161 - acc: 0.7410 - val_loss: 0.5688 - val_acc: 0.7664\n",
      "Epoch 190/300\n",
      "498/498 [==============================] - 0s 146us/step - loss: 0.5360 - acc: 0.7631 - val_loss: 0.5658 - val_acc: 0.7757\n",
      "Epoch 191/300\n",
      "498/498 [==============================] - 0s 244us/step - loss: 0.5174 - acc: 0.7631 - val_loss: 0.5561 - val_acc: 0.7617\n",
      "Epoch 192/300\n",
      "498/498 [==============================] - 0s 242us/step - loss: 0.5228 - acc: 0.7269 - val_loss: 0.5394 - val_acc: 0.7570\n",
      "Epoch 193/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5038 - acc: 0.7871 - val_loss: 0.5281 - val_acc: 0.7477\n",
      "Epoch 194/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.4867 - acc: 0.7871 - val_loss: 0.5233 - val_acc: 0.7570\n",
      "Epoch 195/300\n",
      "498/498 [==============================] - 0s 451us/step - loss: 0.5030 - acc: 0.7751 - val_loss: 0.5250 - val_acc: 0.7477\n",
      "Epoch 196/300\n",
      "498/498 [==============================] - 0s 288us/step - loss: 0.4897 - acc: 0.7892 - val_loss: 0.5371 - val_acc: 0.7710\n",
      "Epoch 197/300\n",
      "498/498 [==============================] - 0s 383us/step - loss: 0.4944 - acc: 0.7912 - val_loss: 0.5442 - val_acc: 0.7757\n",
      "Epoch 198/300\n",
      "498/498 [==============================] - 0s 304us/step - loss: 0.4832 - acc: 0.7892 - val_loss: 0.5471 - val_acc: 0.7804\n",
      "Epoch 199/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5123 - acc: 0.7530 - val_loss: 0.5363 - val_acc: 0.7804\n",
      "Epoch 200/300\n",
      "498/498 [==============================] - 0s 224us/step - loss: 0.5041 - acc: 0.7811 - val_loss: 0.5263 - val_acc: 0.7710\n",
      "Epoch 201/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.4667 - acc: 0.8012 - val_loss: 0.5181 - val_acc: 0.7664\n",
      "Epoch 202/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.5188 - acc: 0.7550 - val_loss: 0.5178 - val_acc: 0.7664\n",
      "Epoch 203/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.4870 - acc: 0.7952 - val_loss: 0.5138 - val_acc: 0.7617\n",
      "Epoch 204/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4999 - acc: 0.7791 - val_loss: 0.5224 - val_acc: 0.7664\n",
      "Epoch 205/300\n",
      "498/498 [==============================] - 0s 240us/step - loss: 0.5156 - acc: 0.7691 - val_loss: 0.5369 - val_acc: 0.7804\n",
      "Epoch 206/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.5039 - acc: 0.7751 - val_loss: 0.5345 - val_acc: 0.7804\n",
      "Epoch 207/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.4934 - acc: 0.7771 - val_loss: 0.5295 - val_acc: 0.7710\n",
      "Epoch 208/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5178 - acc: 0.7631 - val_loss: 0.5339 - val_acc: 0.7757\n",
      "Epoch 209/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5122 - acc: 0.7590 - val_loss: 0.5348 - val_acc: 0.7804\n",
      "Epoch 210/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.5064 - acc: 0.7731 - val_loss: 0.5220 - val_acc: 0.7710\n",
      "Epoch 211/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.4963 - acc: 0.7490 - val_loss: 0.5146 - val_acc: 0.7617\n",
      "Epoch 212/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5040 - acc: 0.7731 - val_loss: 0.5218 - val_acc: 0.7757\n",
      "Epoch 213/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.4949 - acc: 0.7952 - val_loss: 0.5281 - val_acc: 0.7710\n",
      "Epoch 214/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.4908 - acc: 0.7671 - val_loss: 0.5211 - val_acc: 0.7664\n",
      "Epoch 215/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4881 - acc: 0.7691 - val_loss: 0.5141 - val_acc: 0.7664\n",
      "Epoch 216/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.5146 - acc: 0.7771 - val_loss: 0.5178 - val_acc: 0.7617\n",
      "Epoch 217/300\n",
      "498/498 [==============================] - 0s 286us/step - loss: 0.4929 - acc: 0.7831 - val_loss: 0.5264 - val_acc: 0.7757\n",
      "Epoch 218/300\n",
      "498/498 [==============================] - 0s 240us/step - loss: 0.5126 - acc: 0.7530 - val_loss: 0.5431 - val_acc: 0.7804\n",
      "Epoch 219/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5117 - acc: 0.7590 - val_loss: 0.5570 - val_acc: 0.7617\n",
      "Epoch 220/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.4966 - acc: 0.7892 - val_loss: 0.5650 - val_acc: 0.7664\n",
      "Epoch 221/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4917 - acc: 0.7851 - val_loss: 0.5570 - val_acc: 0.7570\n",
      "Epoch 222/300\n",
      "498/498 [==============================] - 0s 198us/step - loss: 0.5064 - acc: 0.7912 - val_loss: 0.5428 - val_acc: 0.7617\n",
      "Epoch 223/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5018 - acc: 0.7570 - val_loss: 0.5276 - val_acc: 0.7804\n",
      "Epoch 224/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5004 - acc: 0.7771 - val_loss: 0.5163 - val_acc: 0.7710\n",
      "Epoch 225/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.4856 - acc: 0.7791 - val_loss: 0.5127 - val_acc: 0.7804\n",
      "Epoch 226/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4834 - acc: 0.7871 - val_loss: 0.5094 - val_acc: 0.7757\n",
      "Epoch 227/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5048 - acc: 0.7751 - val_loss: 0.5124 - val_acc: 0.7804\n",
      "Epoch 228/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.4989 - acc: 0.7731 - val_loss: 0.5135 - val_acc: 0.7804\n",
      "Epoch 229/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4812 - acc: 0.7871 - val_loss: 0.5109 - val_acc: 0.7804\n",
      "Epoch 230/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5039 - acc: 0.7691 - val_loss: 0.5152 - val_acc: 0.7804\n",
      "Epoch 231/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5070 - acc: 0.7731 - val_loss: 0.5144 - val_acc: 0.7897\n",
      "Epoch 232/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4809 - acc: 0.7771 - val_loss: 0.5124 - val_acc: 0.7850\n",
      "Epoch 233/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4587 - acc: 0.7892 - val_loss: 0.5107 - val_acc: 0.7804\n",
      "Epoch 234/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.4799 - acc: 0.7791 - val_loss: 0.5087 - val_acc: 0.7757\n",
      "Epoch 235/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4637 - acc: 0.8052 - val_loss: 0.5041 - val_acc: 0.7757\n",
      "Epoch 236/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.4861 - acc: 0.8012 - val_loss: 0.4969 - val_acc: 0.7804\n",
      "Epoch 237/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.4874 - acc: 0.7871 - val_loss: 0.5000 - val_acc: 0.7757\n",
      "Epoch 238/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5244 - acc: 0.7410 - val_loss: 0.5066 - val_acc: 0.7710\n",
      "Epoch 239/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.4968 - acc: 0.7892 - val_loss: 0.5057 - val_acc: 0.7850\n",
      "Epoch 240/300\n",
      "498/498 [==============================] - 0s 210us/step - loss: 0.5061 - acc: 0.7651 - val_loss: 0.5027 - val_acc: 0.7850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4932 - acc: 0.7731 - val_loss: 0.5026 - val_acc: 0.7757\n",
      "Epoch 242/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.4888 - acc: 0.7851 - val_loss: 0.5079 - val_acc: 0.7710\n",
      "Epoch 243/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.4836 - acc: 0.7972 - val_loss: 0.5086 - val_acc: 0.7710\n",
      "Epoch 244/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5035 - acc: 0.7590 - val_loss: 0.5069 - val_acc: 0.7757\n",
      "Epoch 245/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.4816 - acc: 0.7932 - val_loss: 0.4975 - val_acc: 0.7944\n",
      "Epoch 246/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.4943 - acc: 0.7731 - val_loss: 0.4996 - val_acc: 0.7897\n",
      "Epoch 247/300\n",
      "498/498 [==============================] - 0s 234us/step - loss: 0.5038 - acc: 0.7711 - val_loss: 0.5028 - val_acc: 0.7850\n",
      "Epoch 248/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4687 - acc: 0.8052 - val_loss: 0.5024 - val_acc: 0.7804\n",
      "Epoch 249/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4688 - acc: 0.8052 - val_loss: 0.4963 - val_acc: 0.7804\n",
      "Epoch 250/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.4921 - acc: 0.7892 - val_loss: 0.4952 - val_acc: 0.7850\n",
      "Epoch 251/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4686 - acc: 0.8052 - val_loss: 0.5041 - val_acc: 0.7804\n",
      "Epoch 252/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4685 - acc: 0.7912 - val_loss: 0.5117 - val_acc: 0.7710\n",
      "Epoch 253/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5024 - acc: 0.7590 - val_loss: 0.5027 - val_acc: 0.7804\n",
      "Epoch 254/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.4993 - acc: 0.7791 - val_loss: 0.5102 - val_acc: 0.7710\n",
      "Epoch 255/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4894 - acc: 0.7711 - val_loss: 0.5003 - val_acc: 0.7850\n",
      "Epoch 256/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.4833 - acc: 0.7871 - val_loss: 0.4988 - val_acc: 0.7944\n",
      "Epoch 257/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.4933 - acc: 0.7871 - val_loss: 0.4954 - val_acc: 0.7944\n",
      "Epoch 258/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.4750 - acc: 0.7811 - val_loss: 0.4973 - val_acc: 0.7804\n",
      "Epoch 259/300\n",
      "498/498 [==============================] - 0s 150us/step - loss: 0.4757 - acc: 0.7892 - val_loss: 0.4988 - val_acc: 0.7804\n",
      "Epoch 260/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.4598 - acc: 0.7992 - val_loss: 0.4981 - val_acc: 0.7897\n",
      "Epoch 261/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.4923 - acc: 0.8052 - val_loss: 0.5117 - val_acc: 0.7757\n",
      "Epoch 262/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.4962 - acc: 0.7711 - val_loss: 0.5162 - val_acc: 0.7804\n",
      "Epoch 263/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4758 - acc: 0.7811 - val_loss: 0.5060 - val_acc: 0.7850\n",
      "Epoch 264/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4845 - acc: 0.7992 - val_loss: 0.5022 - val_acc: 0.7850\n",
      "Epoch 265/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.4850 - acc: 0.7851 - val_loss: 0.5042 - val_acc: 0.7850\n",
      "Epoch 266/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.4860 - acc: 0.7912 - val_loss: 0.5098 - val_acc: 0.7757\n",
      "Epoch 267/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4959 - acc: 0.7550 - val_loss: 0.5088 - val_acc: 0.7710\n",
      "Epoch 268/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4656 - acc: 0.7952 - val_loss: 0.5048 - val_acc: 0.7710\n",
      "Epoch 269/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.4825 - acc: 0.7791 - val_loss: 0.4976 - val_acc: 0.7804\n",
      "Epoch 270/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.4715 - acc: 0.8012 - val_loss: 0.5026 - val_acc: 0.7757\n",
      "Epoch 271/300\n",
      "498/498 [==============================] - 0s 150us/step - loss: 0.4694 - acc: 0.7992 - val_loss: 0.5021 - val_acc: 0.7850\n",
      "Epoch 272/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4848 - acc: 0.7811 - val_loss: 0.4979 - val_acc: 0.7897\n",
      "Epoch 273/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.4925 - acc: 0.7811 - val_loss: 0.4896 - val_acc: 0.7897\n",
      "Epoch 274/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4779 - acc: 0.7992 - val_loss: 0.4910 - val_acc: 0.7944\n",
      "Epoch 275/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.4530 - acc: 0.8213 - val_loss: 0.5034 - val_acc: 0.7804\n",
      "Epoch 276/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4942 - acc: 0.7952 - val_loss: 0.5053 - val_acc: 0.7850\n",
      "Epoch 277/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4793 - acc: 0.7711 - val_loss: 0.4948 - val_acc: 0.7897\n",
      "Epoch 278/300\n",
      "498/498 [==============================] - 0s 150us/step - loss: 0.4978 - acc: 0.7791 - val_loss: 0.4904 - val_acc: 0.7897\n",
      "Epoch 279/300\n",
      "498/498 [==============================] - 0s 161us/step - loss: 0.4642 - acc: 0.8153 - val_loss: 0.4935 - val_acc: 0.7897\n",
      "Epoch 280/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4761 - acc: 0.7892 - val_loss: 0.5026 - val_acc: 0.7757\n",
      "Epoch 281/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.4828 - acc: 0.7972 - val_loss: 0.4994 - val_acc: 0.7850\n",
      "Epoch 282/300\n",
      "498/498 [==============================] - 0s 153us/step - loss: 0.4808 - acc: 0.7932 - val_loss: 0.4972 - val_acc: 0.7850\n",
      "Epoch 283/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.4922 - acc: 0.8032 - val_loss: 0.4873 - val_acc: 0.7897\n",
      "Epoch 284/300\n",
      "498/498 [==============================] - 0s 165us/step - loss: 0.4914 - acc: 0.7932 - val_loss: 0.4836 - val_acc: 0.7897\n",
      "Epoch 285/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4627 - acc: 0.7992 - val_loss: 0.4843 - val_acc: 0.7897\n",
      "Epoch 286/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.4680 - acc: 0.7932 - val_loss: 0.4928 - val_acc: 0.7757\n",
      "Epoch 287/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.4757 - acc: 0.7851 - val_loss: 0.4965 - val_acc: 0.7757\n",
      "Epoch 288/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.4637 - acc: 0.8032 - val_loss: 0.4952 - val_acc: 0.7757\n",
      "Epoch 289/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4677 - acc: 0.7831 - val_loss: 0.4904 - val_acc: 0.7850\n",
      "Epoch 290/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4589 - acc: 0.8213 - val_loss: 0.4840 - val_acc: 0.7944\n",
      "Epoch 291/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.4635 - acc: 0.7952 - val_loss: 0.4828 - val_acc: 0.7897\n",
      "Epoch 292/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4596 - acc: 0.8032 - val_loss: 0.4835 - val_acc: 0.7897\n",
      "Epoch 293/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4678 - acc: 0.7751 - val_loss: 0.4857 - val_acc: 0.7850\n",
      "Epoch 294/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4679 - acc: 0.7992 - val_loss: 0.4877 - val_acc: 0.7804\n",
      "Epoch 295/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.4847 - acc: 0.7851 - val_loss: 0.4923 - val_acc: 0.7757\n",
      "Epoch 296/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.4702 - acc: 0.7731 - val_loss: 0.5063 - val_acc: 0.7664\n",
      "Epoch 297/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4728 - acc: 0.7851 - val_loss: 0.4953 - val_acc: 0.7804\n",
      "Epoch 298/300\n",
      "498/498 [==============================] - 0s 146us/step - loss: 0.4793 - acc: 0.7811 - val_loss: 0.4870 - val_acc: 0.7804\n",
      "Epoch 299/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4465 - acc: 0.7972 - val_loss: 0.4790 - val_acc: 0.7944\n",
      "Epoch 300/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4858 - acc: 0.7691 - val_loss: 0.4798 - val_acc: 0.7991\n"
     ]
    }
   ],
   "source": [
    "history = create_network().fit(X_train,Y_train, batch_size=100, epochs = 300, validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, epochs=300,batch_size=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network using three-fold cross-validation\n",
    "CrossValScore = cross_val_score(neural_network, Data_X, Data_Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75       0.79166669 0.74647886 0.81690139 0.78873241 0.77464789\n",
      " 0.78873241 0.78873241 0.78873241 0.84507042]\n",
      "0.7879694879055024\n"
     ]
    }
   ],
   "source": [
    "print (CrossValScore)\n",
    "print( np.mean(CrossValScore) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 418 rows of TEST.CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "print ('Loaded',len(df_test),'rows of TEST.CSV')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title\n",
       "0    Mr\n",
       "1   Mrs\n",
       "2    Mr\n",
       "3    Mr\n",
       "4   Mrs"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = pd.DataFrame()\n",
    "title[ 'Title' ] = df_test[ 'Name' ].map( lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n",
    "title_one = title[ 'Title' ]\n",
    "title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FamilySize\n",
       "0           0\n",
       "1           1\n",
       "2           0\n",
       "3           0\n",
       "4           2"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "family = pd.DataFrame()\n",
    "family['FamilySize'] = df_test['SibSp'] + df_test['Parch']\n",
    "family.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  34.5      0      0   7.8292        Q\n",
       "1       3  female  47.0      1      0   7.0000        S\n",
       "2       2    male  62.0      0      0   9.6875        Q\n",
       "3       3    male  27.0      0      0   8.6625        S\n",
       "4       3  female  22.0      1      1  12.2875        S"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[ ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] ]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 9)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat( [df_test,title_one, family ], axis=1  )\n",
    "df_test.fillna(\"a\")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X = df_test\n",
    "Data_X.to_csv(\"test_processed.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Title  FamilySize\n",
       "0       3    1  34.5      0      0   7.8292         1      2           0\n",
       "1       3    0  47.0      1      0   7.0000         2      3           1\n",
       "2       2    1  62.0      0      0   9.6875         1      2           0\n",
       "3       3    1  27.0      0      0   8.6625         2      2           0\n",
       "4       3    0  22.0      1      1  12.2875         2      3           2"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_X['Sex'] = Data_X['Sex'].map(lambda s: '<unknown>' if s not in labEnc_Sex.classes_ else s)\n",
    "labEnc_Sex.classes_ = np.append(labEnc_Sex.classes_, '<unknown>')\n",
    "\n",
    "Data_X['Embarked'] = Data_X['Embarked'].map(lambda s: '<unknown>' if s not in labEnc_Embarked.classes_ else s)\n",
    "labEnc_Embarked.classes_ = np.append(labEnc_Embarked.classes_, '<unknown>')\n",
    "\n",
    "Data_X['Title'] = Data_X['Title'].map(lambda s: '<unknown>' if s not in labEnc_Title.classes_ else s)\n",
    "labEnc_Title.classes_ = np.append(labEnc_Title.classes_, '<unknown>')\n",
    "\n",
    "Data_X['Sex'] = labEnc_Sex.transform(Data_X.Sex.values)\n",
    "Data_X['Embarked'] = labEnc_Embarked.transform(Data_X.Embarked.values.astype(str))\n",
    "Data_X['Title'] = labEnc_Title.transform(Data_X.Title.values.astype(str))\n",
    "\n",
    "Data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 498 samples, validate on 214 samples\n",
      "Epoch 1/300\n",
      "498/498 [==============================] - 20s 40ms/step - loss: 0.7549 - acc: 0.5663 - val_loss: 0.6847 - val_acc: 0.5467\n",
      "Epoch 2/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.7289 - acc: 0.5643 - val_loss: 0.6797 - val_acc: 0.5561\n",
      "Epoch 3/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.6885 - acc: 0.6084 - val_loss: 0.6734 - val_acc: 0.5701\n",
      "Epoch 4/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.6608 - acc: 0.6546 - val_loss: 0.6646 - val_acc: 0.5701\n",
      "Epoch 5/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.6769 - acc: 0.6064 - val_loss: 0.6574 - val_acc: 0.5888\n",
      "Epoch 6/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.6791 - acc: 0.6245 - val_loss: 0.6503 - val_acc: 0.6075\n",
      "Epoch 7/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.6743 - acc: 0.6124 - val_loss: 0.6447 - val_acc: 0.6262\n",
      "Epoch 8/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.6534 - acc: 0.6406 - val_loss: 0.6390 - val_acc: 0.6589\n",
      "Epoch 9/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.6547 - acc: 0.6285 - val_loss: 0.6331 - val_acc: 0.6542\n",
      "Epoch 10/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.6281 - acc: 0.6566 - val_loss: 0.6292 - val_acc: 0.6729\n",
      "Epoch 11/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.6575 - acc: 0.6386 - val_loss: 0.6246 - val_acc: 0.6776\n",
      "Epoch 12/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.6381 - acc: 0.6466 - val_loss: 0.6200 - val_acc: 0.6729\n",
      "Epoch 13/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.6336 - acc: 0.6446 - val_loss: 0.6171 - val_acc: 0.6822\n",
      "Epoch 14/300\n",
      "498/498 [==============================] - 0s 216us/step - loss: 0.6339 - acc: 0.6526 - val_loss: 0.6141 - val_acc: 0.6963\n",
      "Epoch 15/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.6263 - acc: 0.6526 - val_loss: 0.6116 - val_acc: 0.7056\n",
      "Epoch 16/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.6179 - acc: 0.6606 - val_loss: 0.6091 - val_acc: 0.7103\n",
      "Epoch 17/300\n",
      "498/498 [==============================] - 0s 204us/step - loss: 0.6149 - acc: 0.6767 - val_loss: 0.6070 - val_acc: 0.7150\n",
      "Epoch 18/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.6198 - acc: 0.6827 - val_loss: 0.6044 - val_acc: 0.7103\n",
      "Epoch 19/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.6225 - acc: 0.6767 - val_loss: 0.6025 - val_acc: 0.7056\n",
      "Epoch 20/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.6215 - acc: 0.6747 - val_loss: 0.6012 - val_acc: 0.7009\n",
      "Epoch 21/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.6056 - acc: 0.6948 - val_loss: 0.6005 - val_acc: 0.7009\n",
      "Epoch 22/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.6235 - acc: 0.6767 - val_loss: 0.5998 - val_acc: 0.7009\n",
      "Epoch 23/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.6217 - acc: 0.6687 - val_loss: 0.5994 - val_acc: 0.7009\n",
      "Epoch 24/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.6130 - acc: 0.6747 - val_loss: 0.5989 - val_acc: 0.7009\n",
      "Epoch 25/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.6036 - acc: 0.6847 - val_loss: 0.5984 - val_acc: 0.7009\n",
      "Epoch 26/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.6036 - acc: 0.7068 - val_loss: 0.5976 - val_acc: 0.7009\n",
      "Epoch 27/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.6163 - acc: 0.6727 - val_loss: 0.5968 - val_acc: 0.7150\n",
      "Epoch 28/300\n",
      "498/498 [==============================] - 0s 210us/step - loss: 0.6047 - acc: 0.6647 - val_loss: 0.5966 - val_acc: 0.7150\n",
      "Epoch 29/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.6101 - acc: 0.6687 - val_loss: 0.5962 - val_acc: 0.7150\n",
      "Epoch 30/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.6335 - acc: 0.6627 - val_loss: 0.5962 - val_acc: 0.7150\n",
      "Epoch 31/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.6088 - acc: 0.6888 - val_loss: 0.5954 - val_acc: 0.7150\n",
      "Epoch 32/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.6032 - acc: 0.6867 - val_loss: 0.5947 - val_acc: 0.7150\n",
      "Epoch 33/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5944 - acc: 0.6988 - val_loss: 0.5943 - val_acc: 0.7150\n",
      "Epoch 34/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.6146 - acc: 0.6807 - val_loss: 0.5939 - val_acc: 0.7150\n",
      "Epoch 35/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.6228 - acc: 0.6807 - val_loss: 0.5941 - val_acc: 0.7150\n",
      "Epoch 36/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.6243 - acc: 0.6526 - val_loss: 0.5939 - val_acc: 0.7150\n",
      "Epoch 37/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.5892 - acc: 0.6928 - val_loss: 0.5938 - val_acc: 0.7196\n",
      "Epoch 38/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.6001 - acc: 0.6968 - val_loss: 0.5936 - val_acc: 0.7150\n",
      "Epoch 39/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.6308 - acc: 0.6586 - val_loss: 0.5934 - val_acc: 0.7150\n",
      "Epoch 40/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.5916 - acc: 0.6888 - val_loss: 0.5930 - val_acc: 0.7150\n",
      "Epoch 41/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5982 - acc: 0.6888 - val_loss: 0.5926 - val_acc: 0.7150\n",
      "Epoch 42/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.6038 - acc: 0.6867 - val_loss: 0.5926 - val_acc: 0.7103\n",
      "Epoch 43/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.6114 - acc: 0.6928 - val_loss: 0.5922 - val_acc: 0.7103\n",
      "Epoch 44/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.6073 - acc: 0.6908 - val_loss: 0.5917 - val_acc: 0.7103\n",
      "Epoch 45/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5964 - acc: 0.7108 - val_loss: 0.5911 - val_acc: 0.7103\n",
      "Epoch 46/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5843 - acc: 0.6867 - val_loss: 0.5909 - val_acc: 0.7150\n",
      "Epoch 47/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5885 - acc: 0.6988 - val_loss: 0.5903 - val_acc: 0.7243\n",
      "Epoch 48/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5759 - acc: 0.7048 - val_loss: 0.5898 - val_acc: 0.7243\n",
      "Epoch 49/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.6097 - acc: 0.6988 - val_loss: 0.5897 - val_acc: 0.7243\n",
      "Epoch 50/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.6155 - acc: 0.6827 - val_loss: 0.5895 - val_acc: 0.7150\n",
      "Epoch 51/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.6231 - acc: 0.6787 - val_loss: 0.5892 - val_acc: 0.7150\n",
      "Epoch 52/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5995 - acc: 0.7048 - val_loss: 0.5886 - val_acc: 0.7196\n",
      "Epoch 53/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.6011 - acc: 0.7108 - val_loss: 0.5883 - val_acc: 0.7196\n",
      "Epoch 54/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.5954 - acc: 0.6867 - val_loss: 0.5873 - val_acc: 0.7150\n",
      "Epoch 55/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5964 - acc: 0.6988 - val_loss: 0.5863 - val_acc: 0.7103\n",
      "Epoch 56/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5714 - acc: 0.7229 - val_loss: 0.5858 - val_acc: 0.7103\n",
      "Epoch 57/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5723 - acc: 0.7169 - val_loss: 0.5847 - val_acc: 0.7150\n",
      "Epoch 58/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.6065 - acc: 0.6948 - val_loss: 0.5845 - val_acc: 0.7150\n",
      "Epoch 59/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5901 - acc: 0.6928 - val_loss: 0.5844 - val_acc: 0.7103\n",
      "Epoch 60/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5897 - acc: 0.7068 - val_loss: 0.5843 - val_acc: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.5916 - acc: 0.6827 - val_loss: 0.5844 - val_acc: 0.7103\n",
      "Epoch 62/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5911 - acc: 0.6968 - val_loss: 0.5844 - val_acc: 0.7150\n",
      "Epoch 63/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5930 - acc: 0.6827 - val_loss: 0.5843 - val_acc: 0.7103\n",
      "Epoch 64/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5758 - acc: 0.6908 - val_loss: 0.5837 - val_acc: 0.7103\n",
      "Epoch 65/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5904 - acc: 0.6888 - val_loss: 0.5823 - val_acc: 0.7056\n",
      "Epoch 66/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.5896 - acc: 0.6948 - val_loss: 0.5811 - val_acc: 0.7056\n",
      "Epoch 67/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5923 - acc: 0.7068 - val_loss: 0.5807 - val_acc: 0.7056\n",
      "Epoch 68/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.5900 - acc: 0.7108 - val_loss: 0.5805 - val_acc: 0.7103\n",
      "Epoch 69/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.5705 - acc: 0.7129 - val_loss: 0.5795 - val_acc: 0.7103\n",
      "Epoch 70/300\n",
      "498/498 [==============================] - 0s 201us/step - loss: 0.6061 - acc: 0.6968 - val_loss: 0.5798 - val_acc: 0.7056\n",
      "Epoch 71/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5898 - acc: 0.7149 - val_loss: 0.5808 - val_acc: 0.7056\n",
      "Epoch 72/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5870 - acc: 0.7088 - val_loss: 0.5818 - val_acc: 0.7103\n",
      "Epoch 73/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5824 - acc: 0.7169 - val_loss: 0.5825 - val_acc: 0.7009\n",
      "Epoch 74/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5785 - acc: 0.6968 - val_loss: 0.5836 - val_acc: 0.7103\n",
      "Epoch 75/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5761 - acc: 0.7088 - val_loss: 0.5832 - val_acc: 0.7103\n",
      "Epoch 76/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5886 - acc: 0.7129 - val_loss: 0.5833 - val_acc: 0.7103\n",
      "Epoch 77/300\n",
      "498/498 [==============================] - 0s 148us/step - loss: 0.5781 - acc: 0.7189 - val_loss: 0.5830 - val_acc: 0.7103\n",
      "Epoch 78/300\n",
      "498/498 [==============================] - 0s 150us/step - loss: 0.5843 - acc: 0.6988 - val_loss: 0.5805 - val_acc: 0.7009\n",
      "Epoch 79/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5975 - acc: 0.6867 - val_loss: 0.5787 - val_acc: 0.7009\n",
      "Epoch 80/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.5835 - acc: 0.7068 - val_loss: 0.5774 - val_acc: 0.7056\n",
      "Epoch 81/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5750 - acc: 0.7028 - val_loss: 0.5774 - val_acc: 0.7056\n",
      "Epoch 82/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5789 - acc: 0.7068 - val_loss: 0.5777 - val_acc: 0.7056\n",
      "Epoch 83/300\n",
      "498/498 [==============================] - 0s 165us/step - loss: 0.5747 - acc: 0.7108 - val_loss: 0.5785 - val_acc: 0.7056\n",
      "Epoch 84/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5590 - acc: 0.7209 - val_loss: 0.5793 - val_acc: 0.7056\n",
      "Epoch 85/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5633 - acc: 0.7209 - val_loss: 0.5795 - val_acc: 0.7056\n",
      "Epoch 86/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5917 - acc: 0.6968 - val_loss: 0.5788 - val_acc: 0.7056\n",
      "Epoch 87/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5706 - acc: 0.7149 - val_loss: 0.5770 - val_acc: 0.7150\n",
      "Epoch 88/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.5780 - acc: 0.7008 - val_loss: 0.5763 - val_acc: 0.7150\n",
      "Epoch 89/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5561 - acc: 0.7129 - val_loss: 0.5761 - val_acc: 0.7150\n",
      "Epoch 90/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5569 - acc: 0.7068 - val_loss: 0.5742 - val_acc: 0.7150\n",
      "Epoch 91/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5698 - acc: 0.6988 - val_loss: 0.5715 - val_acc: 0.7150\n",
      "Epoch 92/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5770 - acc: 0.7209 - val_loss: 0.5681 - val_acc: 0.7103\n",
      "Epoch 93/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5534 - acc: 0.7369 - val_loss: 0.5698 - val_acc: 0.7103\n",
      "Epoch 94/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5662 - acc: 0.7189 - val_loss: 0.5713 - val_acc: 0.7150\n",
      "Epoch 95/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5594 - acc: 0.7249 - val_loss: 0.5700 - val_acc: 0.7150\n",
      "Epoch 96/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5633 - acc: 0.7088 - val_loss: 0.5734 - val_acc: 0.7196\n",
      "Epoch 97/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5746 - acc: 0.7229 - val_loss: 0.5759 - val_acc: 0.7150\n",
      "Epoch 98/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5669 - acc: 0.7289 - val_loss: 0.5770 - val_acc: 0.7196\n",
      "Epoch 99/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5626 - acc: 0.7209 - val_loss: 0.5766 - val_acc: 0.7150\n",
      "Epoch 100/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5719 - acc: 0.7249 - val_loss: 0.5774 - val_acc: 0.7103\n",
      "Epoch 101/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5620 - acc: 0.7309 - val_loss: 0.5768 - val_acc: 0.7056\n",
      "Epoch 102/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5544 - acc: 0.7349 - val_loss: 0.5754 - val_acc: 0.7009\n",
      "Epoch 103/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.5626 - acc: 0.7289 - val_loss: 0.5759 - val_acc: 0.6963\n",
      "Epoch 104/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5698 - acc: 0.7249 - val_loss: 0.5744 - val_acc: 0.6963\n",
      "Epoch 105/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5479 - acc: 0.7289 - val_loss: 0.5700 - val_acc: 0.7009\n",
      "Epoch 106/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5469 - acc: 0.7410 - val_loss: 0.5669 - val_acc: 0.7009\n",
      "Epoch 107/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5605 - acc: 0.7249 - val_loss: 0.5687 - val_acc: 0.7009\n",
      "Epoch 108/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5625 - acc: 0.7209 - val_loss: 0.5703 - val_acc: 0.7056\n",
      "Epoch 109/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.5761 - acc: 0.7108 - val_loss: 0.5720 - val_acc: 0.6963\n",
      "Epoch 110/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5425 - acc: 0.7450 - val_loss: 0.5731 - val_acc: 0.7056\n",
      "Epoch 111/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.5639 - acc: 0.7249 - val_loss: 0.5737 - val_acc: 0.7056\n",
      "Epoch 112/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5554 - acc: 0.7169 - val_loss: 0.5704 - val_acc: 0.7009\n",
      "Epoch 113/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5518 - acc: 0.7169 - val_loss: 0.5744 - val_acc: 0.6963\n",
      "Epoch 114/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.5617 - acc: 0.7269 - val_loss: 0.5753 - val_acc: 0.7056\n",
      "Epoch 115/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5397 - acc: 0.7129 - val_loss: 0.5739 - val_acc: 0.7009\n",
      "Epoch 116/300\n",
      "498/498 [==============================] - 0s 214us/step - loss: 0.5492 - acc: 0.7349 - val_loss: 0.5691 - val_acc: 0.7056\n",
      "Epoch 117/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5449 - acc: 0.7329 - val_loss: 0.5693 - val_acc: 0.7103\n",
      "Epoch 118/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5490 - acc: 0.7410 - val_loss: 0.5707 - val_acc: 0.7103\n",
      "Epoch 119/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5417 - acc: 0.7410 - val_loss: 0.5702 - val_acc: 0.7056\n",
      "Epoch 120/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5474 - acc: 0.7329 - val_loss: 0.5693 - val_acc: 0.7056\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 [==============================] - 0s 200us/step - loss: 0.5637 - acc: 0.7108 - val_loss: 0.5657 - val_acc: 0.7103\n",
      "Epoch 122/300\n",
      "498/498 [==============================] - 0s 200us/step - loss: 0.5262 - acc: 0.7470 - val_loss: 0.5626 - val_acc: 0.7103\n",
      "Epoch 123/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5412 - acc: 0.7088 - val_loss: 0.5557 - val_acc: 0.7243\n",
      "Epoch 124/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.5291 - acc: 0.7550 - val_loss: 0.5508 - val_acc: 0.7336\n",
      "Epoch 125/300\n",
      "498/498 [==============================] - 0s 194us/step - loss: 0.5223 - acc: 0.7550 - val_loss: 0.5489 - val_acc: 0.7290\n",
      "Epoch 126/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5246 - acc: 0.7530 - val_loss: 0.5464 - val_acc: 0.7290\n",
      "Epoch 127/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5435 - acc: 0.7550 - val_loss: 0.5447 - val_acc: 0.7243\n",
      "Epoch 128/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5478 - acc: 0.7309 - val_loss: 0.5414 - val_acc: 0.7336\n",
      "Epoch 129/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5444 - acc: 0.7490 - val_loss: 0.5386 - val_acc: 0.7383\n",
      "Epoch 130/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5230 - acc: 0.7651 - val_loss: 0.5372 - val_acc: 0.7150\n",
      "Epoch 131/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5287 - acc: 0.7390 - val_loss: 0.5390 - val_acc: 0.7243\n",
      "Epoch 132/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.5238 - acc: 0.7490 - val_loss: 0.5398 - val_acc: 0.7243\n",
      "Epoch 133/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5263 - acc: 0.7610 - val_loss: 0.5396 - val_acc: 0.7243\n",
      "Epoch 134/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.5487 - acc: 0.7129 - val_loss: 0.5375 - val_acc: 0.7243\n",
      "Epoch 135/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5170 - acc: 0.7610 - val_loss: 0.5353 - val_acc: 0.7383\n",
      "Epoch 136/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5292 - acc: 0.7369 - val_loss: 0.5304 - val_acc: 0.7430\n",
      "Epoch 137/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5078 - acc: 0.7711 - val_loss: 0.5252 - val_acc: 0.7430\n",
      "Epoch 138/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.5370 - acc: 0.7450 - val_loss: 0.5284 - val_acc: 0.7523\n",
      "Epoch 139/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5160 - acc: 0.7369 - val_loss: 0.5312 - val_acc: 0.7477\n",
      "Epoch 140/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5219 - acc: 0.7289 - val_loss: 0.5304 - val_acc: 0.7430\n",
      "Epoch 141/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5027 - acc: 0.7671 - val_loss: 0.5254 - val_acc: 0.7430\n",
      "Epoch 142/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5151 - acc: 0.7731 - val_loss: 0.5242 - val_acc: 0.7430\n",
      "Epoch 143/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5111 - acc: 0.7510 - val_loss: 0.5197 - val_acc: 0.7336\n",
      "Epoch 144/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5162 - acc: 0.7631 - val_loss: 0.5217 - val_acc: 0.7336\n",
      "Epoch 145/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5103 - acc: 0.7590 - val_loss: 0.5311 - val_acc: 0.7477\n",
      "Epoch 146/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5458 - acc: 0.7610 - val_loss: 0.5212 - val_acc: 0.7477\n",
      "Epoch 147/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5088 - acc: 0.7771 - val_loss: 0.5151 - val_acc: 0.7383\n",
      "Epoch 148/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5148 - acc: 0.7711 - val_loss: 0.5152 - val_acc: 0.7336\n",
      "Epoch 149/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5129 - acc: 0.7450 - val_loss: 0.5107 - val_acc: 0.7430\n",
      "Epoch 150/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5081 - acc: 0.7751 - val_loss: 0.5108 - val_acc: 0.7477\n",
      "Epoch 151/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5098 - acc: 0.7610 - val_loss: 0.5125 - val_acc: 0.7477\n",
      "Epoch 152/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5325 - acc: 0.7510 - val_loss: 0.5135 - val_acc: 0.7430\n",
      "Epoch 153/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5291 - acc: 0.7590 - val_loss: 0.5104 - val_acc: 0.7477\n",
      "Epoch 154/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5331 - acc: 0.7349 - val_loss: 0.5096 - val_acc: 0.7477\n",
      "Epoch 155/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5252 - acc: 0.7349 - val_loss: 0.5070 - val_acc: 0.7477\n",
      "Epoch 156/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.5061 - acc: 0.7450 - val_loss: 0.5074 - val_acc: 0.7570\n",
      "Epoch 157/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4973 - acc: 0.7631 - val_loss: 0.5103 - val_acc: 0.7523\n",
      "Epoch 158/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5025 - acc: 0.7550 - val_loss: 0.5121 - val_acc: 0.7383\n",
      "Epoch 159/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5022 - acc: 0.7631 - val_loss: 0.5125 - val_acc: 0.7383\n",
      "Epoch 160/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.5155 - acc: 0.7631 - val_loss: 0.5100 - val_acc: 0.7430\n",
      "Epoch 161/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5080 - acc: 0.7590 - val_loss: 0.5068 - val_acc: 0.7430\n",
      "Epoch 162/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.5130 - acc: 0.7530 - val_loss: 0.5048 - val_acc: 0.7430\n",
      "Epoch 163/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5073 - acc: 0.7590 - val_loss: 0.5012 - val_acc: 0.7477\n",
      "Epoch 164/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.4872 - acc: 0.7731 - val_loss: 0.4991 - val_acc: 0.7570\n",
      "Epoch 165/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5212 - acc: 0.7570 - val_loss: 0.4996 - val_acc: 0.7617\n",
      "Epoch 166/300\n",
      "498/498 [==============================] - 0s 148us/step - loss: 0.5378 - acc: 0.7510 - val_loss: 0.5038 - val_acc: 0.7477\n",
      "Epoch 167/300\n",
      "498/498 [==============================] - 0s 159us/step - loss: 0.5086 - acc: 0.7490 - val_loss: 0.5079 - val_acc: 0.7336\n",
      "Epoch 168/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.5032 - acc: 0.7711 - val_loss: 0.5118 - val_acc: 0.7336\n",
      "Epoch 169/300\n",
      "498/498 [==============================] - 0s 152us/step - loss: 0.5107 - acc: 0.7510 - val_loss: 0.5152 - val_acc: 0.7336\n",
      "Epoch 170/300\n",
      "498/498 [==============================] - 0s 155us/step - loss: 0.5174 - acc: 0.7470 - val_loss: 0.5056 - val_acc: 0.7477\n",
      "Epoch 171/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5304 - acc: 0.7530 - val_loss: 0.4984 - val_acc: 0.7664\n",
      "Epoch 172/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4815 - acc: 0.7811 - val_loss: 0.4925 - val_acc: 0.7664\n",
      "Epoch 173/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4949 - acc: 0.7972 - val_loss: 0.4901 - val_acc: 0.7664\n",
      "Epoch 174/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5002 - acc: 0.7570 - val_loss: 0.4935 - val_acc: 0.7617\n",
      "Epoch 175/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5086 - acc: 0.7530 - val_loss: 0.4942 - val_acc: 0.7664\n",
      "Epoch 176/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5049 - acc: 0.7590 - val_loss: 0.4917 - val_acc: 0.7710\n",
      "Epoch 177/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.4742 - acc: 0.8032 - val_loss: 0.4862 - val_acc: 0.7757\n",
      "Epoch 178/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5256 - acc: 0.7510 - val_loss: 0.4851 - val_acc: 0.7710\n",
      "Epoch 179/300\n",
      "498/498 [==============================] - 0s 196us/step - loss: 0.4955 - acc: 0.7811 - val_loss: 0.4922 - val_acc: 0.7570\n",
      "Epoch 180/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5073 - acc: 0.7711 - val_loss: 0.4981 - val_acc: 0.7570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.4932 - acc: 0.7590 - val_loss: 0.4939 - val_acc: 0.7617\n",
      "Epoch 182/300\n",
      "498/498 [==============================] - 0s 160us/step - loss: 0.5243 - acc: 0.7450 - val_loss: 0.4958 - val_acc: 0.7617\n",
      "Epoch 183/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5194 - acc: 0.7510 - val_loss: 0.4985 - val_acc: 0.7570\n",
      "Epoch 184/300\n",
      "498/498 [==============================] - 0s 159us/step - loss: 0.5073 - acc: 0.7490 - val_loss: 0.5034 - val_acc: 0.7570\n",
      "Epoch 185/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5084 - acc: 0.7490 - val_loss: 0.5117 - val_acc: 0.7523\n",
      "Epoch 186/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5105 - acc: 0.7691 - val_loss: 0.5175 - val_acc: 0.7430\n",
      "Epoch 187/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5064 - acc: 0.7610 - val_loss: 0.5116 - val_acc: 0.7477\n",
      "Epoch 188/300\n",
      "498/498 [==============================] - 0s 164us/step - loss: 0.5093 - acc: 0.7631 - val_loss: 0.5009 - val_acc: 0.7523\n",
      "Epoch 189/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5452 - acc: 0.7189 - val_loss: 0.4926 - val_acc: 0.7617\n",
      "Epoch 190/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.5078 - acc: 0.7791 - val_loss: 0.4954 - val_acc: 0.7570\n",
      "Epoch 191/300\n",
      "498/498 [==============================] - 0s 159us/step - loss: 0.4815 - acc: 0.7751 - val_loss: 0.4969 - val_acc: 0.7523\n",
      "Epoch 192/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4969 - acc: 0.7570 - val_loss: 0.5003 - val_acc: 0.7477\n",
      "Epoch 193/300\n",
      "498/498 [==============================] - 0s 192us/step - loss: 0.5227 - acc: 0.7390 - val_loss: 0.4948 - val_acc: 0.7523\n",
      "Epoch 194/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5163 - acc: 0.7610 - val_loss: 0.4910 - val_acc: 0.7570\n",
      "Epoch 195/300\n",
      "498/498 [==============================] - 0s 154us/step - loss: 0.5123 - acc: 0.7590 - val_loss: 0.4916 - val_acc: 0.7570\n",
      "Epoch 196/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5152 - acc: 0.7510 - val_loss: 0.4939 - val_acc: 0.7570\n",
      "Epoch 197/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.5182 - acc: 0.7671 - val_loss: 0.4921 - val_acc: 0.7617\n",
      "Epoch 198/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5064 - acc: 0.7570 - val_loss: 0.4883 - val_acc: 0.7664\n",
      "Epoch 199/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4857 - acc: 0.7871 - val_loss: 0.4885 - val_acc: 0.7664\n",
      "Epoch 200/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.4946 - acc: 0.7811 - val_loss: 0.4907 - val_acc: 0.7664\n",
      "Epoch 201/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5258 - acc: 0.7671 - val_loss: 0.4915 - val_acc: 0.7664\n",
      "Epoch 202/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4880 - acc: 0.7892 - val_loss: 0.4892 - val_acc: 0.7664\n",
      "Epoch 203/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5042 - acc: 0.7811 - val_loss: 0.4886 - val_acc: 0.7664\n",
      "Epoch 204/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.4947 - acc: 0.7751 - val_loss: 0.4889 - val_acc: 0.7617\n",
      "Epoch 205/300\n",
      "498/498 [==============================] - 0s 158us/step - loss: 0.5087 - acc: 0.7610 - val_loss: 0.4922 - val_acc: 0.7664\n",
      "Epoch 206/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5030 - acc: 0.7831 - val_loss: 0.4912 - val_acc: 0.7617\n",
      "Epoch 207/300\n",
      "498/498 [==============================] - 0s 166us/step - loss: 0.4699 - acc: 0.7992 - val_loss: 0.4801 - val_acc: 0.7710\n",
      "Epoch 208/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5147 - acc: 0.7470 - val_loss: 0.4762 - val_acc: 0.7710\n",
      "Epoch 209/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.5049 - acc: 0.7771 - val_loss: 0.4781 - val_acc: 0.7664\n",
      "Epoch 210/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4788 - acc: 0.7932 - val_loss: 0.4840 - val_acc: 0.7710\n",
      "Epoch 211/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5164 - acc: 0.7369 - val_loss: 0.4936 - val_acc: 0.7617\n",
      "Epoch 212/300\n",
      "498/498 [==============================] - 0s 156us/step - loss: 0.4907 - acc: 0.7570 - val_loss: 0.4985 - val_acc: 0.7664\n",
      "Epoch 213/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4948 - acc: 0.7671 - val_loss: 0.4829 - val_acc: 0.7664\n",
      "Epoch 214/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.4910 - acc: 0.7751 - val_loss: 0.4767 - val_acc: 0.7664\n",
      "Epoch 215/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4760 - acc: 0.7751 - val_loss: 0.4767 - val_acc: 0.7710\n",
      "Epoch 216/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5043 - acc: 0.7771 - val_loss: 0.4851 - val_acc: 0.7664\n",
      "Epoch 217/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4917 - acc: 0.7651 - val_loss: 0.4890 - val_acc: 0.7617\n",
      "Epoch 218/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.5049 - acc: 0.7651 - val_loss: 0.4837 - val_acc: 0.7710\n",
      "Epoch 219/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.5079 - acc: 0.7651 - val_loss: 0.4867 - val_acc: 0.7617\n",
      "Epoch 220/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4776 - acc: 0.7791 - val_loss: 0.4822 - val_acc: 0.7664\n",
      "Epoch 221/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.4961 - acc: 0.7651 - val_loss: 0.4787 - val_acc: 0.7617\n",
      "Epoch 222/300\n",
      "498/498 [==============================] - 0s 162us/step - loss: 0.5037 - acc: 0.7791 - val_loss: 0.4768 - val_acc: 0.7617\n",
      "Epoch 223/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4876 - acc: 0.7691 - val_loss: 0.4769 - val_acc: 0.7664\n",
      "Epoch 224/300\n",
      "498/498 [==============================] - 0s 177us/step - loss: 0.5020 - acc: 0.7530 - val_loss: 0.4806 - val_acc: 0.7664\n",
      "Epoch 225/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4720 - acc: 0.7871 - val_loss: 0.4809 - val_acc: 0.7664\n",
      "Epoch 226/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4921 - acc: 0.7851 - val_loss: 0.4792 - val_acc: 0.7664\n",
      "Epoch 227/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.5217 - acc: 0.7450 - val_loss: 0.4787 - val_acc: 0.7710\n",
      "Epoch 228/300\n",
      "498/498 [==============================] - 0s 170us/step - loss: 0.5240 - acc: 0.7570 - val_loss: 0.4814 - val_acc: 0.7710\n",
      "Epoch 229/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.5094 - acc: 0.7731 - val_loss: 0.4895 - val_acc: 0.7664\n",
      "Epoch 230/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4997 - acc: 0.7651 - val_loss: 0.4961 - val_acc: 0.7710\n",
      "Epoch 231/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.5093 - acc: 0.7711 - val_loss: 0.4893 - val_acc: 0.7710\n",
      "Epoch 232/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4977 - acc: 0.7691 - val_loss: 0.4880 - val_acc: 0.7664\n",
      "Epoch 233/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4570 - acc: 0.7992 - val_loss: 0.4831 - val_acc: 0.7664\n",
      "Epoch 234/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.4970 - acc: 0.7751 - val_loss: 0.4798 - val_acc: 0.7664\n",
      "Epoch 235/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.4959 - acc: 0.7751 - val_loss: 0.4813 - val_acc: 0.7664\n",
      "Epoch 236/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4897 - acc: 0.7851 - val_loss: 0.4796 - val_acc: 0.7664\n",
      "Epoch 237/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4662 - acc: 0.7851 - val_loss: 0.4818 - val_acc: 0.7664\n",
      "Epoch 238/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4852 - acc: 0.7771 - val_loss: 0.4820 - val_acc: 0.7664\n",
      "Epoch 239/300\n",
      "498/498 [==============================] - 0s 202us/step - loss: 0.4890 - acc: 0.7751 - val_loss: 0.4822 - val_acc: 0.7710\n",
      "Epoch 240/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4932 - acc: 0.7892 - val_loss: 0.4868 - val_acc: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4797 - acc: 0.7671 - val_loss: 0.4878 - val_acc: 0.7710\n",
      "Epoch 242/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.4811 - acc: 0.7691 - val_loss: 0.4879 - val_acc: 0.7664\n",
      "Epoch 243/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.4760 - acc: 0.7831 - val_loss: 0.4869 - val_acc: 0.7664\n",
      "Epoch 244/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4939 - acc: 0.7590 - val_loss: 0.4858 - val_acc: 0.7617\n",
      "Epoch 245/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5187 - acc: 0.7711 - val_loss: 0.4895 - val_acc: 0.7617\n",
      "Epoch 246/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.5072 - acc: 0.7631 - val_loss: 0.4905 - val_acc: 0.7664\n",
      "Epoch 247/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4751 - acc: 0.7871 - val_loss: 0.4857 - val_acc: 0.7664\n",
      "Epoch 248/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4861 - acc: 0.7791 - val_loss: 0.4837 - val_acc: 0.7617\n",
      "Epoch 249/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4839 - acc: 0.7631 - val_loss: 0.4850 - val_acc: 0.7617\n",
      "Epoch 250/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4946 - acc: 0.7610 - val_loss: 0.4874 - val_acc: 0.7710\n",
      "Epoch 251/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4798 - acc: 0.7912 - val_loss: 0.4876 - val_acc: 0.7664\n",
      "Epoch 252/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.4831 - acc: 0.7831 - val_loss: 0.4856 - val_acc: 0.7664\n",
      "Epoch 253/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.4899 - acc: 0.7671 - val_loss: 0.4822 - val_acc: 0.7664\n",
      "Epoch 254/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4723 - acc: 0.7892 - val_loss: 0.4789 - val_acc: 0.7664\n",
      "Epoch 255/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.4865 - acc: 0.7871 - val_loss: 0.4774 - val_acc: 0.7710\n",
      "Epoch 256/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5161 - acc: 0.7590 - val_loss: 0.4765 - val_acc: 0.7710\n",
      "Epoch 257/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4817 - acc: 0.7831 - val_loss: 0.4796 - val_acc: 0.7664\n",
      "Epoch 258/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.5089 - acc: 0.7791 - val_loss: 0.4861 - val_acc: 0.7710\n",
      "Epoch 259/300\n",
      "498/498 [==============================] - 0s 181us/step - loss: 0.5094 - acc: 0.7731 - val_loss: 0.4906 - val_acc: 0.7664\n",
      "Epoch 260/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4898 - acc: 0.7831 - val_loss: 0.4933 - val_acc: 0.7664\n",
      "Epoch 261/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.4806 - acc: 0.7851 - val_loss: 0.4972 - val_acc: 0.7617\n",
      "Epoch 262/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4887 - acc: 0.7851 - val_loss: 0.4984 - val_acc: 0.7570\n",
      "Epoch 263/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.5006 - acc: 0.7831 - val_loss: 0.4944 - val_acc: 0.7617\n",
      "Epoch 264/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4847 - acc: 0.7912 - val_loss: 0.4909 - val_acc: 0.7617\n",
      "Epoch 265/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4877 - acc: 0.7892 - val_loss: 0.4890 - val_acc: 0.7710\n",
      "Epoch 266/300\n",
      "498/498 [==============================] - 0s 184us/step - loss: 0.4779 - acc: 0.8072 - val_loss: 0.4880 - val_acc: 0.7664\n",
      "Epoch 267/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4832 - acc: 0.7751 - val_loss: 0.4885 - val_acc: 0.7664\n",
      "Epoch 268/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4831 - acc: 0.7771 - val_loss: 0.4938 - val_acc: 0.7664\n",
      "Epoch 269/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4952 - acc: 0.7892 - val_loss: 0.4890 - val_acc: 0.7664\n",
      "Epoch 270/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4927 - acc: 0.7811 - val_loss: 0.4794 - val_acc: 0.7757\n",
      "Epoch 271/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4873 - acc: 0.7831 - val_loss: 0.4796 - val_acc: 0.7757\n",
      "Epoch 272/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4694 - acc: 0.7892 - val_loss: 0.4788 - val_acc: 0.7804\n",
      "Epoch 273/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4709 - acc: 0.7871 - val_loss: 0.4787 - val_acc: 0.7757\n",
      "Epoch 274/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.4623 - acc: 0.8092 - val_loss: 0.4862 - val_acc: 0.7664\n",
      "Epoch 275/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4913 - acc: 0.7892 - val_loss: 0.4927 - val_acc: 0.7664\n",
      "Epoch 276/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4816 - acc: 0.7751 - val_loss: 0.4868 - val_acc: 0.7757\n",
      "Epoch 277/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4893 - acc: 0.7811 - val_loss: 0.4862 - val_acc: 0.7710\n",
      "Epoch 278/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.5061 - acc: 0.7791 - val_loss: 0.4860 - val_acc: 0.7710\n",
      "Epoch 279/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4682 - acc: 0.7972 - val_loss: 0.4865 - val_acc: 0.7664\n",
      "Epoch 280/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4748 - acc: 0.7831 - val_loss: 0.4891 - val_acc: 0.7664\n",
      "Epoch 281/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4777 - acc: 0.7892 - val_loss: 0.4914 - val_acc: 0.7664\n",
      "Epoch 282/300\n",
      "498/498 [==============================] - 0s 182us/step - loss: 0.4866 - acc: 0.7831 - val_loss: 0.4946 - val_acc: 0.7710\n",
      "Epoch 283/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4647 - acc: 0.7992 - val_loss: 0.5000 - val_acc: 0.7617\n",
      "Epoch 284/300\n",
      "498/498 [==============================] - 0s 168us/step - loss: 0.4627 - acc: 0.8012 - val_loss: 0.4913 - val_acc: 0.7664\n",
      "Epoch 285/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4991 - acc: 0.7871 - val_loss: 0.4831 - val_acc: 0.7710\n",
      "Epoch 286/300\n",
      "498/498 [==============================] - 0s 175us/step - loss: 0.4846 - acc: 0.7831 - val_loss: 0.4845 - val_acc: 0.7710\n",
      "Epoch 287/300\n",
      "498/498 [==============================] - 0s 172us/step - loss: 0.4799 - acc: 0.7791 - val_loss: 0.4931 - val_acc: 0.7570\n",
      "Epoch 288/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.5031 - acc: 0.7711 - val_loss: 0.4937 - val_acc: 0.7570\n",
      "Epoch 289/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4572 - acc: 0.7851 - val_loss: 0.4937 - val_acc: 0.7523\n",
      "Epoch 290/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.4595 - acc: 0.8112 - val_loss: 0.4887 - val_acc: 0.7570\n",
      "Epoch 291/300\n",
      "498/498 [==============================] - 0s 178us/step - loss: 0.4859 - acc: 0.7771 - val_loss: 0.4929 - val_acc: 0.7617\n",
      "Epoch 292/300\n",
      "498/498 [==============================] - 0s 180us/step - loss: 0.4817 - acc: 0.7892 - val_loss: 0.4926 - val_acc: 0.7664\n",
      "Epoch 293/300\n",
      "498/498 [==============================] - 0s 176us/step - loss: 0.4954 - acc: 0.7871 - val_loss: 0.4925 - val_acc: 0.7617\n",
      "Epoch 294/300\n",
      "498/498 [==============================] - 0s 174us/step - loss: 0.4745 - acc: 0.7912 - val_loss: 0.5068 - val_acc: 0.7523\n",
      "Epoch 295/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.4959 - acc: 0.7671 - val_loss: 0.5154 - val_acc: 0.7430\n",
      "Epoch 296/300\n",
      "498/498 [==============================] - 0s 188us/step - loss: 0.4771 - acc: 0.7731 - val_loss: 0.5080 - val_acc: 0.7430\n",
      "Epoch 297/300\n",
      "498/498 [==============================] - 0s 206us/step - loss: 0.4791 - acc: 0.7892 - val_loss: 0.4954 - val_acc: 0.7617\n",
      "Epoch 298/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.4672 - acc: 0.7851 - val_loss: 0.4850 - val_acc: 0.7617\n",
      "Epoch 299/300\n",
      "498/498 [==============================] - 0s 186us/step - loss: 0.4542 - acc: 0.8072 - val_loss: 0.4810 - val_acc: 0.7757\n",
      "Epoch 300/300\n",
      "498/498 [==============================] - 0s 190us/step - loss: 0.4899 - acc: 0.7871 - val_loss: 0.4804 - val_acc: 0.7710\n"
     ]
    }
   ],
   "source": [
    "# Start neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(18,input_dim=9))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(10))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('selu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train,Y_train, batch_size=100, epochs = 300, validation_data = (X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = model.predict(Data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramvinojen\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for x in pred_Y:\n",
    "    if x > .5 :\n",
    "        pred_Y[count] = 1\n",
    "    else:\n",
    "       pred_Y[count] = 0\n",
    "    count = count + 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'output':pred_Y[:,0]})\n",
    "df.to_csv(\"test_y.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
